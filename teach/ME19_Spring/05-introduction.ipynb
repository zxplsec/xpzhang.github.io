{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绪论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习算法：\n",
    "   $$\\boldsymbol  y = \\boldsymbol y(\\boldsymbol x; \\boldsymbol w)$$，\n",
    "    其中$\\boldsymbol w$为模型参数\n",
    "\n",
    "  * 输入：$\\boldsymbol x$ - 数字向量\n",
    "  * 输出：$\\boldsymbol y$ - 数字标签，表示类别\n",
    "  * 训练集(trainning set)：$\\{\\boldsymbol x_1,\\cdots,\\boldsymbol x_N\\}$，数字类别已知，通常为人工标注，用目标向量(target vector) $\\boldsymbol t$表示\n",
    "  * 测试集(test set)：新的数字图像集合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 机器学习方法的分类 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 监督学习（supervised learning）：训练数据的样本包含输入变量$\\vec x$及对应的目标变量$\\vec t$\n",
    "  * 回归（regression）：对数值型连续随机变量进行预测和建模的监督学习算法\n",
    "  * 分类 (classification)：对离散型随机变量建模或预测的监督学习算法\n",
    "  \n",
    "  \n",
    "* 无监督学习（unsupervised learning）\n",
    "  * 聚类（clustering）：发现数据中相似样本的分组\n",
    "  * 密度估计（density estimation）：确定输入空间中数据的分布\n",
    "  * 数据可视化（visualization）：把数据从高维空间投影到二维或三维空间\n",
    "  \n",
    "\n",
    "* 强化学习 （reinforcement learning）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多项式拟合 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定一个训练集，由 $x$ 的 $N$ 次观测组成，记为 $\\mathbf x = (x_1, \\cdots, x_N)^T$，对应的目标向量为 $\\mathbf t = (t_1,\\cdots,t_N)^T$。 \n",
    "\n",
    "<img src=\"image/Figure1.2.png\"  width = 50% height = 50%  />\n",
    "\n",
    "$x_n$ 均匀分布在 $[0,1]$，$\\mathbf t$ 的获取方式为：先计算 $\\sin(2\\pi x)$ 的值，然后给每个点加上一个小的服从高斯分布的随机噪声。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的目标是：利用该训练集来预测新的 $\\hat x$ 对应的目标值 $\\hat t$。\n",
    "\n",
    "下面将讨论多项式拟合：\n",
    "$$\n",
    "y(x; \\boldsymbol w) = \\sum_{j=0}^M w_jx^j, \\quad  \\boldsymbol w = (w_0, \\cdots, w_M)\n",
    "$$\n",
    "\n",
    "\n",
    "注意：虽然 $y(x; \\boldsymbol w)$ 是关于 $x$ 的一个非线性函数，但它却是关于系数 $\\boldsymbol w$ 的一个线性函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\boldsymbol w$ 的值可通过最小化误差函数（error function）的方式来确定。误差函数衡量了给定 $\\boldsymbol w$ 时 $y(\\mathbf x; \\boldsymbol w)$ 与 $\\mathbf t$ 的差异。最常用的误差函数为：\n",
    "$$\n",
    "E(\\boldsymbol w) = \\frac12 \\sum_{n=1}^N \\{y(x_n; \\boldsymbol w)-t_n\\}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.3.png\"  width = 50% height = 50%  />\n",
    "\n",
    "此时曲线拟合问题可描述为：寻找 $\\boldsymbol w$ 使得 $E(\\boldsymbol w)$ 尽可能的小。注意到 $E(\\boldsymbol w)$ 是关于 $\\boldsymbol w$ 的二次函数，故其导数是关于 $\\boldsymbol w$ 的线性函数，从而 $E(\\boldsymbol w)$ 存在唯一的极小值点，记为 $\\boldsymbol w^*$。该过程可用最小二乘法来求解。最终确定的多项式由 $y(x; \\boldsymbol w^*)$ 给出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何确定多项式的次数 $M$，这涉及到所谓的模型选择（Model Selection）问题。下图给出了多项式次数分别为 $M=0,1,3,9$ 时的拟合效果。\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.4a.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.4b.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.4c.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.4d.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上图可以看出：\n",
    "\n",
    "* 当 $M=0$ 和 $M=1$ 时，拟合效果非常差，这种现象称为**欠拟合**（under-fitting）。\n",
    "* 当 $M=3$ 时，拟合效果比较好。\n",
    "* 当 $M=9$ 时，多项式函数经过了每一个数据点，即 $E(\\boldsymbol w^*)=0$。然而，此时拟合曲线震荡剧烈，无法表达函数 $\\sin(2\\pi x)$。这种现象称为**过拟合**（over-fitting）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请记住我们的目标，希望所得到的模型对新数据的预测有良好的泛化性能（Generalization）。现在我们来定量地考察泛化性能与 $M$ 之间的关系。\n",
    "\n",
    "\n",
    "考虑一个额外的测试集，它由 $100$ 个数据点组成，其生成方式与训练集完全相同，但目标值所包含的噪声不同。\n",
    "分别在训练集和测试集上计算均方根误差（Rooted Mean Square）\n",
    " $$\n",
    " E_{RMS}(\\boldsymbol w) =  \\sqrt{ \\frac1N \\sum_{n=1}^N \\{y(x_n; \\boldsymbol w)-t_n\\}^2}\n",
    " = \\sqrt{2E(\\boldsymbol w)/N}\n",
    " $$\n",
    "\n",
    "选用均方根误差的原因：\n",
    "\n",
    "* 除以 $N$ 可以对不同规模的数据集做度量\n",
    "* 平方根确保尺度的一致性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 下图展示了当 $M$ 去不同的值时，训练数据和测试数据的均方根误差。\n",
    "\n",
    "<img src=\"image/Figure1.5.png\"  width = 50% height = 50%  />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 当 $M$ 较小时，测试误差较大，因训练出的模型欠拟合。\n",
    "\n",
    "* 当 $3 \\le M \\le 8$ 时，测试误差较小，拟合效果较好。\n",
    "\n",
    "* 当 $M = 9$ 时，训练误差为 $0$，但测试误差很大，对应的 $y(x; \\boldsymbol w^*)$ 有强烈的震荡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察选取不同的 $M$ 时，拟合多项式系数 $\\boldsymbol w^*$ 的值。\n",
    "\n",
    "<img src=\"image/Table1.1.png\"  width = 50% height = 50%  />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 随着 $M$ 的增大，系数变得越来越大。\n",
    "* 当 $M = 9$ 时，通过调节系数，让系数取绝对值很大的正数或负数，多项式与数据点精确匹配，但对于数据之间的点表现出了强烈的震荡。\n",
    "\n",
    "直觉上来看，当模型变得复杂时（即 $M$ 较大），过分调参使得多项式更倾向于拟合目标值的随机噪声。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对一个给定复杂度的模型，当数据集规模增加时，过拟合现象会有所缓解。换句话说，数据集规模越大，能拟合数据的模型就可以越复杂。\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.6a.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.6b.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但很多情况下，数据规模是有限的，用上述方式控制过拟合就不可行。\n",
    "\n",
    "还有一种控制过拟合现象的技术叫做正则化（Regularization），它在误差函数上加上一个惩罚项（Penalty term），使得系数不会变成很大的数。最简单的形式如下：\n",
    "$$\n",
    "\\tilde E(\\boldsymbol w) = \\frac12 \\sum_{n=1}^N \\{y(x_n; \\boldsymbol w)-t_n\\}^2 + \\frac\\lambda 2 \\|\\boldsymbol w\\|^2\n",
    "$$\n",
    "其中 $\\lambda$ 控制惩罚项的重要性。最小化上述误差函数可用解析的方式求解。\n",
    "\n",
    "* 在统计学中，该方法称为收缩法（shrinkage method），因为它减小了系数的值。\n",
    "* 在神经网络中，该方法称为权值衰减（weight decay）\n",
    "* 有时也称山脊回归（Ridge regession）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.7a.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.7b.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "当 $M=9$ 时，正则化方法的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Table1.2.png\" width = 50% height = 50% />\n",
    "\n",
    "$M=9$ 时，不同正则化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 概率论 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.9.png\" width = 50% height = 50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有两个盒子（box），一个红色（red），一个蓝色(blue)，其中红盒中有2个苹果（apple）和6个橙子（orange），蓝盒中有3个苹果（apple）和1个橙子（orange）。随机选择一个盒子，从中随机选择一个水果，然后放回盒子中，这样重复很多次。假设有40%的时间选择红盒，60%的时间选择蓝盒，并且选择哪一种水果是等可能性的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义所选择盒子的颜色为一个随机变量$B$，其可能选值为$r$（red box）和$b$（blue box）。定义水果的种类为另一个随机变量$F$，其可能选值为$a$（apple）和$o$（orange）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，把一个事件的概率定义成事件发生的次数与试验总数的比值，并假设总试验次数趋于无穷。因此，\n",
    "$$\n",
    "p(B=r) = \\frac4{10}, \\quad\n",
    "p(B=b) = \\frac6{10}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题1：选到苹果的整体概率是多少？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率论的两条基本准则：\n",
    "\n",
    "* 加法原理（sum rule）\n",
    "\n",
    "* 乘法原理（product rule）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有两个随机变量$X$和$Y$，\n",
    "\n",
    "<img src=\"image/Figure1.10.png\" width = 50% height = 50% />\n",
    "其中$X$可从$\\{x_i, i=1,\\cdots,M\\}$中选值，$Y$可从$\\{y_j, j=1,\\cdots, L\\}$选值。考虑$N$次试验，对$X$和$Y$均进行采样，记\n",
    "\n",
    "* 事件$X=x_i$和$Y=y_j$的试验次数为$n_{ij}$\n",
    "\n",
    "* 事件$X=x_i$的试验次数为$c_i$\n",
    "\n",
    "* 事件$Y=y_j$的试验次数为$r_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 几个重要概念：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 联合概率（joint probability）\n",
    "\n",
    "  $X=x_i$且$Y=y_j$的概率记作$p(X=x_i, Y=y_j)$，称为$X=x_i$和$Y=y_j$的联合概率。\n",
    "  \n",
    "  其值等于：落在单元格$(i,j)$中的样本数与总样本数的比值，即\n",
    "  $$\n",
    "  p(X=x_i, Y=y_j) = \\frac{n_{ij}}{N}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 边缘概率（marginal probability）\n",
    "\n",
    "  $X=x_i$的概率记作$P(X=x_i)$，称为边缘概率。\n",
    "  \n",
    "  其值等于：落在第$i$列的样本数与总样本数的比值，即\n",
    "  $$\n",
    "  p(X=x_i)=\\frac{c_i}N\n",
    "  $$\n",
    "  \n",
    "  因为$c_i=\\sum_j n_{ij}$，故\n",
    "  $$\n",
    "  p(X=x_i) = \\frac{c_i}N = \\sum_j \\frac{n_{ij}}N = \\sum_j  p(X=x_i, Y=y_j)\n",
    "  $$\n",
    "  此即概率的加法原则（sum rule）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 条件概率（conditional probability）\n",
    "\n",
    "  只考虑$X=x_i$的样本，这些样本中$Y=y_j$的样本所占的比例记为$p(Y=y_j|X=x_i)$，称为给定$X=x_i$的条件下$Y=y_j$的条件概率。\n",
    "  \n",
    "  其值等于：落在单元格$(i,j)$中的样本数与总样本数的比值，即\n",
    "  $$\n",
    "  p(Y=y_j|X=x_i)=\\frac{n_{ij}}{c_i}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由以上关系式可以推出：\n",
    "$$\n",
    "p(X=x_i, Y=y_j) = \\frac{n_{ij}}N =  \\frac{n_{ij}}{c_i} \\cdot \\frac{c_i}N =  p(Y=y_j|X=x_i)  p(X=x_i)\n",
    "$$\n",
    "此即概率的乘法原则(product rule)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**一些记号**\n",
    "\n",
    "* $p(B = r)$：$B$取值为$r$的概率\n",
    "\n",
    "* $p(B)$：随机变量$B$的分布\n",
    "\n",
    "* $p(r)$：这个分布对特定值$r$的估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率论的两条基本准则：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(X) &= \\sum_Y p(X, Y)\\\\\n",
    "p(X, Y) &= p(Y | X)  p(X)\n",
    "\\end{aligned}\n",
    "$$\n",
    "这里\n",
    "\n",
    "* $p(X, Y)$是联合概率，表示“$X且Y$的概率”\n",
    "* $p(Y|X)$是条件概率，表示“给定$X$的条件下$Y$的概率”\n",
    "* $p(X)$是边缘概率，表示“$X$的概率”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯定理（Bayes' theorem） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由联合概率的对称性，即$p(X, Y)=p(Y, X)$以及乘法原则，可得\n",
    "$$\n",
    "p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}\n",
    "$$\n",
    "它被称为贝叶斯定理，在机器学习领域扮演着非常核心的角色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再利用加法原则可知\n",
    "$$\n",
    "p(X) = \\sum_Y p(X, Y) = \\sum_Y p(X|Y)p(Y)\n",
    "$$\n",
    "这说明上式的分母可用分子中出现的项来表示，它可看做是归一化常数，保证条件概率关于所有$Y$的取值之和为$1$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.11a.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.11b.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.11c.png\" width = 80% height = 80% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.11d.png\" width = 80% height = 80% /></center></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到之前“从盒子中去水果”的例子。有如下结论："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 选红盒或蓝盒的概率 \n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(B=r) &= \\frac4{10} \\\\\n",
    "P(B=b) &= \\frac6{10}\n",
    "\\end{aligned}\n",
    "$$\n",
    "注意： \n",
    "$$\n",
    "p(B=r)+p(B=b)=1 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.9.png\" width = 50% height = 50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 选定一个盒子后，选某种水果的概率：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(F=a|B=r) &= \\frac14 \\\\\n",
    "p(F=o|B=r) &= \\frac34 \\\\\n",
    "p(F=a|B=b) &= \\frac34 \\\\\n",
    "p(F=o|B=b) &= \\frac14\n",
    "\\end{aligned}\n",
    "$$\n",
    "注意\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(F=a|B=r)+p(F=o|B=r) &= 1 \\\\\n",
    "p(F=a|B=b)+p(F=o|B=b) &= 1\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，可以回答之前提出的两个问题。\n",
    "\n",
    "* 利用加法原则和乘法原则，可计算出**挑选一个苹果的整体概率**：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(F=a) & = p(F=a | B=r) p(B=r) + p(F=a | B=b) p(B=b) \\\\\n",
    "& = \\frac{1}{4} \\times \\frac{4}{10} + \\frac{3}{4} \\times \\frac{6}{10} = \\frac{11}{20}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "再利用加法原则，可知\n",
    "$$\n",
    "p(F=o) = 1 - p(F=a) = \\frac9{20}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果已知挑选的水果是橙子，它来自某个盒子的可能性有多大？\n",
    "\n",
    "这可由贝叶斯定理求得，即\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(B=r|F=o)  = \\frac{p(F=o|B=r)p(B=r)}{p(F=o)} = \\frac{\\frac34 \\times \\frac4{10}}{\\frac9{20}}=\\frac23.\n",
    "\\end{aligned}\n",
    "$$\n",
    "由加法原则，\n",
    "$$\n",
    "p(B=b|F=o)=1-p(B=r|F=o)=1-\\frac23=\\frac13.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新表述贝叶斯定理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以从盒子中挑选水果为例。\n",
    "\n",
    "* 先验概率$p(B)$： 观察到$F$之前就能得到的概率\n",
    "\n",
    "\n",
    "* 后验概率$P(B|F)$：观察到$F$之后的概率，可通过贝叶斯定理来计算\n",
    "\n",
    "在该例中，\n",
    "\n",
    "* 选择红盒的先验概率是$\\frac4{10}$，即选择蓝盒的可能性更大。\n",
    "\n",
    "* 若挑选的是橙子，则选择红盒的后验概率为$\\frac23$，此时选择红盒的可能性更大。\n",
    "\n",
    "这个结论符合我们的直觉，因为红盒中橙子的比例高于蓝盒，所以“观察到水果是橙子”这一事件提供了更有利的证据来选择红盒。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立事件 \n",
    "\n",
    "若两个变量的联合分布可以分解成两个边缘分布的乘积，即\n",
    "$$\n",
    "p(X, Y) = p(X) p(Y)\n",
    "$$\n",
    "则称$X$与$Y$相互独立（independent）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据乘法原则可得\n",
    "$$\n",
    "p(Y|X) = p(Y),\n",
    "$$\n",
    "这说明对于给定$X$条件下$Y$的条件分布独立于$X$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例：若两个盒子中苹果和橙子数相同，则$p(F|B)=P(F)$，从而选择苹果的概率与选择哪个盒子无关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概率密度 \n",
    "\n",
    "这里我们考虑与连续变量相关的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"image/Figure1.12.png\" width = 50% height = 50% /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果一个实值变量$x$的概率落在区间$(x, x+\\delta x)$的概率由$p(x)\\delta x$给定$(\\delta x\\to 0)$，则称$p(x)$为$x$的概率密度（probability density）。\n",
    "\n",
    "$x$位于区间$(a,b)$的概率为\n",
    "$$\n",
    "p(x\\in(a, b)) = \\int_a^b p(x) \\,dx.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率密度满足以下两个条件：\n",
    "$$\n",
    "p(x)\\ge 0, \\quad\n",
    "\\int_{-\\infty}^{\\infty} p(x)\\,dx = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 累计分布函数（cummulative distribution function）\n",
    "\n",
    "称$(-\\infty, z)$中$x$的概率\n",
    "$$\n",
    "P(z) = \\int_{-\\infty}^z p(x)\\,dx \n",
    "$$\n",
    "为累计分布函数，它满足\n",
    "$$\n",
    "P'(x)=p(x)。\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于连续随机向量$\\boldsymbol x=(x_1,\\cdots,x_d)^T$，可定义**联合概率密度**$p(\\boldsymbol x)=p(x_1,\\cdots,x_d)$，使得$\\boldsymbol x$落在包含点$\\boldsymbol x$的无穷小体积$\\delta \\boldsymbol x$的概率由$p(\\boldsymbol x)\\delta \\boldsymbol x$给出。联合概率密度满足：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(\\boldsymbol x)\\ge 0 \\\\\n",
    "\\int p(\\boldsymbol x)\\,d\\boldsymbol x = 1\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率的加法原则、乘法原则以及贝叶斯定理，同样可以应用于概率密度函数的情形。例如，若$x$和$y$是两个实变量，则加法原则与乘法原则的形式为\n",
    "$$\n",
    "p(x) = \\int p(x,y)\\,dy \\\\\n",
    "p(x, y) = p(x|y) p(y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 期望和协方差 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 期望\n",
    "\n",
    "在概率分布$p(x)$下，函数$f(x)$的平均值称为$f(x)$的期望，记为$\\mathbb E[f]$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对于离散变量，其定义为\n",
    "   $$\n",
    "   \\mathbb E[f] = \\sum_x p(x) f(x)\n",
    "   $$\n",
    "  \n",
    "* 对于连续变量，其定义为\n",
    "   $$\n",
    "   \\mathbb E[f] = \\int p(x)f(x)\\,dx\n",
    "   $$\n",
    "  \n",
    "  对以上两种情形，给定有限的$N$个点，若这些点满足某个概率分布或概率密度函数，则期望可通过下式进行估计：\n",
    "  $$\n",
    "  \\mathbb E[f] \\approx \\frac1N \\sum_{n=1}^N f(x_n)\n",
    "  $$\n",
    "  当$N\\to \\infty$，上式会变得越来也精确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**多变量函数的期望**\n",
    "\n",
    "通常使用下标来表示对哪个变量进行加权平均，如\n",
    "$$\n",
    "\\mathbb E_x [f(x, y)]  \n",
    "$$\n",
    "表示函数$f(x, y)$关于变量$x$的平均，它是关于$y$的一个函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**条件期望**\n",
    "\n",
    "可定义一个条件概率分布的条件期望（conditional expection）,即\n",
    "* 离散变量：\n",
    "$$\n",
    "E_x[f|y] = \\sum_x p(x|y) f(x) \n",
    "$$\n",
    "* 连续变量：\n",
    "$$\n",
    "E_x[f|y] = \\int p(x|y) f(x) \\,dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方差 \n",
    "\n",
    "函数$f(x)$的方差(variance)被定义为\n",
    "$$\n",
    "\\mathrm{var}  [f] = \\mathbb E[\\left(f(x) - \\mathbb E[f(x)]\\right)^2]\n",
    "$$\n",
    "它度量了$f(x)$在均值$\\mathbb E[f(x)]$附近的变化程度。进一步分析可知\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{var}  [f] &= \\mathbb E[\\left(f(x) - \\mathbb E[f(x)]\\right)^2]\\\\\n",
    "&= \\mathbb E[f^2(x) - 2\\mathbb E[f(x)] f(x) + \\mathbb E[f(x)]^2]\\\\\n",
    "&= \\mathbb E[f^2(x)] - 2\\mathbb E[f(x)]^2+ \\mathbb E[f(x)]^2\\\\\n",
    "&= \\mathbb E[f^2(x)] - \\mathbb E[f(x)]^2,\n",
    "\\end{aligned}\n",
    "$$\n",
    "即\n",
    "$$\n",
    "\\mathrm{var}  [f] = \\mathbb E[f^2] - \\mathbb E[f]^2,\n",
    "$$\n",
    "这说明，$f$的方差可通过$f$和$f^2$的期望表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特别地，若$f\\equiv x$，则\n",
    "$$\n",
    "\\mathrm{var}[x] = \\mathbb E[x^2] -\\mathbb E[x]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 协方差\n",
    "\n",
    "对于两个随机变量$x$和$y$，协方差（covariance ）被定义为\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{cov}[x, y] &= \\mathbb E_{x,y}[\\{x-\\mathbb E(x)\\}\\{y-\\mathbb E(y)\\}]\\\\\n",
    "&= \\mathbb E_{x,y}[xy - \\mathbb E(y) x - \\mathbb E(x) y + \\mathbb E(x)\\mathbb E(y) ]\\\\\n",
    "&= \\mathbb E_{x,y}[xy] - \\mathbb E[x]\\mathbb E[y]\n",
    "\\end{aligned}\n",
    "$$\n",
    "用于衡量$x$与$y$的总体误差。如果$x$与$y$相互独立，则它们的协方差为$0$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在两个随机向量$\\boldsymbol x$和$\\boldsymbol y$的情形下，协方差为一个矩阵\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathrm{cov} [\\boldsymbol x, \\boldsymbol y] &=  \\mathbb E_{\\boldsymbol x,\\boldsymbol y}[\\{\\boldsymbol x-\\mathbb E(\\boldsymbol x)\\}\\{\\boldsymbol y^T-\\mathbb E(\\boldsymbol y^T)\\}]\\\\\n",
    "&=  \\mathbb E_{\\boldsymbol x,\\boldsymbol y}[\\boldsymbol x \\boldsymbol y^T-\\boldsymbol x \\mathbb E(\\boldsymbol y^T)-\\mathbb E(\\boldsymbol x) \\boldsymbol y^T+\\mathbb E(\\boldsymbol x) \\mathbb E(\\boldsymbol y^T)]\\\\\n",
    "&=\\mathbb E_{\\boldsymbol x,\\boldsymbol y}[\\boldsymbol x \\boldsymbol y^T]-\\mathbb E(\\boldsymbol x) \\mathbb E(\\boldsymbol y^T)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯概率 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 经典（classic）或频率学家（frequentist）观点：根据随机重复事件的频率来考察概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 贝叶斯（Bayesian）观点：更加通用，在此观点下，频率提供了不确定性的一种定量化描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考察不确定性事件，如\n",
    "* 月球是否曾经围绕太阳转\n",
    "* 本世纪末北极冰盖是否会消失\n",
    "\n",
    "这些事件无法重复，从而无法像“从盒子中取水果”那样定义概率。但是，通常我们希望知道一些信息，如北极冰盖融化的速度等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在“从盒中取水果”的例子中，水果种类的观察提供了相关信息，改变了选择红盒的概率。\n",
    "利用贝叶斯定理，融合观察到的信息，把先验概率转化成了后验概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在观测到数据之前，若有关于参数$\\boldsymbol w$的假设，将以先验概率$p(\\boldsymbol w)$的形式给出。观测数据$\\mathcal D=\\{t_1, \\cdots, t_N\\}$使得其可以通过条件概率$p(\\mathcal D|\\boldsymbol w)$的形式表达。贝叶斯定理的形式为\n",
    "$$ \n",
    "p(\\boldsymbol w | \\mathcal D) = \\frac{p(\\mathcal D|\\boldsymbol w) p(\\boldsymbol w)}{p(\\mathcal D)} \\tag {1}\n",
    "$$\n",
    "它让我们能通过后验概率$p(\\boldsymbol w | \\mathcal D)$，在观测到$\\mathcal D$后来估计$\\boldsymbol w$的不确定性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\mathcal D|\\boldsymbol w)$由观测数据$\\mathcal D$来估计，可以看做是参数$\\boldsymbol w$的函数，被称为似然函数（likelihood function）。它表达了在不同的参数$\\boldsymbol w$下，观测数据出现的可能性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：似然函数不是$\\boldsymbol w$的概率分布，且它关于$\\boldsymbol w$的积分不一定为$1$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若给定了似然函数的定义，则贝叶斯定理可表示为\n",
    "$$\n",
    "\\mathrm{posterior} \\varpropto \\mathrm{likelihood} \\times \\mathrm{prior}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对（1）两侧关于$\\boldsymbol w$求积分，可得\n",
    "$$\n",
    "1 = \\int p(\\boldsymbol w | \\mathcal D) \\,d\\boldsymbol w = \\frac{\\int p(\\mathcal D|\\boldsymbol w) p(\\boldsymbol w) \\,d\\boldsymbol w}{p(\\mathcal D)} \\tag {1}\n",
    "$$\n",
    "从而有\n",
    "$$\n",
    "p(\\mathcal D)=\\int p(\\mathcal D|\\boldsymbol w) p(\\boldsymbol w) \\,d\\boldsymbol w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在贝叶斯观点和频率学家观点中，似然函数$p(\\mathcal D|\\boldsymbol w)$都起着重要的作用。然而，在两种观点 中，使用的方式有着本质的不同。\n",
    "\n",
    "* 在频率学家眼中，$\\boldsymbol w$被认为是一个固定的参数，它的值由某种形式的“估计”来确定，这个估计的误差通过考察可能的数据集$\\mathcal D$的概率分布来得到。\n",
    "* 从贝叶斯观点来看，只有一个数据集$\\mathcal D$(即实际观测到的数据集)，参数的不确定性通过$\\boldsymbol w$的概率分布来表达。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯分布（Gaussian distribution） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一元实值变量$x$，高斯分布被定义为\n",
    "$$\n",
    "\\mathcal N(x | \\mu, \\sigma^2) = \\frac1{(2\\pi\\sigma^2)^{1/2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "它由两个参数控制：均值（mean）$\\mu$和方差（variance）$\\sigma^2$。\n",
    "* 方差的平方根$\\sigma$称为标准差（standard deviation）；\n",
    "* 方差的倒数$\\beta = \\sigma^{-2}$称为精度（precision）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.13.png\" width = 50% height = 50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然，高斯分布满足\n",
    "\n",
    "*  $\\mathcal N(x|\\mu,\\sigma^2)>0$\n",
    "*  $\\int_{-\\infty}^\\infty \\mathcal N(x|\\mu,\\sigma^2)\\,dx = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb E[x] = \\int_{-\\infty}^\\infty \\mathcal N(x|\\mu,\\sigma^2) x\\,dx = \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb E[x] &= \\int_{-\\infty}^\\infty \\mathcal N(x|\\mu,\\sigma^2) x\\,dx \\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} x\\,dx\\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} (x-\\mu) \\,dx+\\mu \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\,dx\\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{t^2}{2\\sigma^2}} t\\,dt+\\mu \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\,dx\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中第一项的被积函数为基函数，积分区间对称，故第一项的积分值为零；而由高斯分布的特点值第二项中的积分值为$1$。故结论得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb E[x^2] = \\int_{-\\infty}^\\infty \\mathcal N(x|\\mu,\\sigma^2) x^2\\,dx = \\mu^2+\\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb E[x^2] &= \\int_{-\\infty}^\\infty \\mathcal N(x|\\mu,\\sigma^2) x^2\\,dx \\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} x^2\\,dx\\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} (x-\\mu)^2 \\,dx+2\\mu \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} (x-\\mu) \\,dx+\\mu^2 \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\,dx\\\\\n",
    "&= \\int_{-\\infty}^\\infty \\frac1{(2\\pi\\sigma^2)^{1/2}} e^{-\\frac{t^2}{2\\sigma^2}} t^2\\,dt+\\mu^2\\\\\n",
    "&=\\sigma^2+\\mu^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{var}[x] = \\mathbb E[x^2] - \\mathrm E[x]^2 = \\sigma^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布的最大值称为众数。对于高斯分布，均值与众数刚好相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $D$维向量的高斯分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal N(\\boldsymbol x | \\boldsymbol \\mu, \\boldsymbol \\Sigma) = \\frac1{(2\\pi)^{D/2}} \\frac1{|\\boldsymbol \\Sigma|^{1/2}}\n",
    "\\exp\\left\\{-\\frac12(\\boldsymbol x-\\boldsymbol\\mu)^T\\boldsymbol\\Sigma^{-1}(\\boldsymbol x-\\boldsymbol\\mu)\\right\\}\n",
    "$$\n",
    "其中\n",
    "\n",
    "* $\\boldsymbol \\mu \\in \\mathbb R^d$为均值\n",
    "* $\\boldsymbol \\Sigma \\in \\mathbb R^{d\\times d}$为协方差\n",
    "* $|\\boldsymbol \\Sigma|$表示$\\boldsymbol \\Sigma$的行列式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有一个观测数据集$\\mathcal D = \\{\\boldsymbol x_1, \\cdots, \\boldsymbol x_N\\}$，表示变量$\\boldsymbol x$的$N$次观测。\n",
    "\n",
    "注意这里的记号：\n",
    "\n",
    "* $\\mathcal D$表示数据集\n",
    "* $\\boldsymbol x = (x^{(1)}, \\cdots, x^{(d)})^T$表示样本（或者观测点）的维数。若维数为1，用$x$表示。\n",
    "\n",
    "以下只考虑一维数据，此时观测数据集表示为$\\mathcal D = \\{ x_1, \\cdots,  x_N\\}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**假定每次观测都是从高斯分布中抽取的，分布的均值$\\mu$和方差$\\sigma^2$未知，我们想从数据集中来估计这些参数。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "独立同分布（Independent and identically distributed，i.i.d.）是指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意两个独立事件的联合概率等于各个事件边缘概率的乘积，而数据集 $\\mathcal D$ 是独立同分布的，故我们可以给出数据集的联合概率：\n",
    "$$\n",
    "p(\\mathcal D | \\mu, \\sigma^2) = \\prod_{n=1}^N p(x_n | \\mu, \\sigma^2) \n",
    "$$\n",
    "若把它看做是$\\mu$和$\\sigma^2$的函数，则称它为高斯分布的似然函数（likelihood function）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.14.png\" width = 50% height = 50% />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 黑色点表示数据集$\\{x_n\\}$的值\n",
    "* 蓝色点表示每个数据点所对应的概率\n",
    "* 似然函数对应于蓝色值的乘积\n",
    "\n",
    "极大化似然函数意味着需要确定参数$\\mu$和$\\sigma^2$，使得这个乘积最大。确定了$\\mu$和$\\sigma^2$后，对应的高斯分布就可以确定，即得图中的红线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极大似然估计 （maximum likelihood estimate, MLE）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过极大化似然函数\n",
    "$$\n",
    "p(\\mathbf x | \\mu, \\sigma^2) = \\prod_{n=1}^N p(x_n | \\mu, \\sigma^2) \n",
    "$$\n",
    "来确定高斯分布中的参数$\\mu$和$\\sigma^2$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际应用中，我们更倾向考虑**对数似然函数**，这是因为对数函数单调递增，极大化某个函数的对数等价于极大化它本身。\n",
    "\n",
    "上式的对数似然函数为\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ln p(\\mathbf x | \\mu, \\sigma^2) & = \\sum_{n=1}^N \\ln \\mathcal N(x_n | \\mu, \\sigma^2) \n",
    "= \\sum_{n=1}^N \\ln \\frac1{(2\\pi\\sigma^2)^{1/2}} \\exp\\left(-\\frac{(x_n-\\mu)^2}{2\\sigma^2}\\right)\\\\\n",
    "& = -\\frac{1}{2\\sigma^2} \\sum_{n=1}^N (x_n-\\mu)^2 - \\frac N2 \\ln \\sigma^2 - \\frac N2 \\ln (2\\pi)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对上式分别关于$\\mu$和$\\sigma^2$求偏导，可得\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\ln p(\\mathbf x | \\mu, \\sigma^2)}{\\partial \\mu} \n",
    "& = -\\frac{1}{\\sigma^2} \\sum_{n=1}^N (x_n-\\mu)\\\\\n",
    "\\frac{\\partial \\ln p(\\mathbf x | \\mu, \\sigma^2)}{\\partial \\sigma^2} \n",
    "& =  \\frac{1}{2\\sigma^4} \\sum_{n=1}^N (x_n-\\mu)^2 - \\frac N2 \\frac1{\\sigma^2}\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此可知，极大值点（这里称为极大似然解）为\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{ML} &= \\frac{1}{N} \\sum_{n=1}^N x_n \\\\\n",
    "\\sigma_{ML}^2 & = \\frac1N \\sum_{n=1}^N (x_n-\\mu_{ML})^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "其中\n",
    "* $\\mu_{ML}$为样本均值（sample mean），即观测值$\\{x_n\\}$的均值\n",
    "* $\\sigma_{ML}^2$是关于样本均值$\\mu_{ML}$的样本方差（sample variance）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极大似然估计系统性地低估了分布的方差，这是偏差（bias）现象的一个例子，与多项式曲线拟合问题的过拟合现象相关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意到极大似然解$\\mu_{ML}$和$\\sigma_{ML}^2$是关于数据点$x_1,\\cdots,x_n$的函数，我们来考虑它们关于数据集的数学期望。容易证明：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb E[\\mu_{ML}] &=\\mu, \\\\\n",
    "\\mathbb E[\\sigma_{ML}^2] & = \\frac{N-1}{N} \\sigma^2.\n",
    "\\end{aligned}\n",
    "$$\n",
    "这说明极大似然估计的均值就是分布的均值，但将会低估方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明：\n",
    "\n",
    "关于$\\mu_{ML}$，有\n",
    "$$\n",
    "\\mathbb E[\\mu_{ML}] = \\mathbb E\\left[\\frac{1}{N} \\sum_{n=1}^N x_n\\right] \n",
    "=\\frac{1}{N} \\sum_{n=1}^N \\mathbb E[x_n]  =\\frac{1}{N} (N\\mu) = \\mu\n",
    "$$\n",
    "关于$\\sigma^2_{ML}$，有\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb E[\\sigma^2_{ML}] &= \\mathbb E\\left[\\frac1N \\sum_{n=1}^N (x_n-\\mu_{ML})^2\\right] \\\\\n",
    "&= \\mathbb E\\left[\\frac1N \\sum_{n=1}^N x_n^2-\\mu_{ML}^2\\right] \\\\\n",
    "&= \\frac1N \\sum_{n=1}^N \\mathbb E\\left[ x_n^2\\right]-\\mathbb E\\left[\\mu_{ML}^2\\right]\\\\\n",
    "&= (\\sigma^2 + \\mu^2) - \\frac1{N^2}\\left(N^2\\mu^2+N\\sigma^2\\right)\\\\\n",
    "&=\\frac{N-1}N\\sigma^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.15.png\" width = 50% height = 50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，当数据集的规模$N$增大时，极大似然估计的偏移不会太严重，并且当$N\\to \\infty$时，方差的极大似然解与产生数据的分布的真实方差相等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新考察曲线拟合问题 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前，针对曲线拟合问题，我们通过最小化平方误差进行了讨论。现在，我们从概率论的角度进行考察。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "曲线拟合问题的目标是：通过由$N$个输入$\\mathbf = \\{x_1, \\cdots, x_N\\}$组成的数据集以及对应的目标值$\\mathbf t = \\{t_1, \\cdots, t_N\\}$，给定新的输入$x$，对其目标变量$t$进行预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，我们用概率分布来表达目标变量的不确定性。为此，假设给定$x$的值，对应的$t$服从高斯分布，且分布的均值为\n",
    "$$\n",
    "y(x;\\boldsymbol w) = \\sum_{j=0}^M w_j x^j.\n",
    "$$\n",
    "于是，\n",
    "$$\n",
    "p(t|x, \\boldsymbol w, \\beta) = \\mathcal N(t | y(x, \\boldsymbol w), \\beta^{-1}),\n",
    "$$\n",
    "这里定义精度参数$\\beta$，它等于方差的倒数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/Figure1.16.png\" width = 50% height = 50% />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在用训练数据$\\{\\mathbf x, \\mathbf t\\}$，通过极大似然方法来确定未知参数$\\boldsymbol w$和$\\beta$的值。\n",
    "\n",
    "若假定数据从上述分布中抽样得到，则似然函数为\n",
    "$$\n",
    "p(\\mathbf t | \\mathbf x, \\boldsymbol w, \\beta) = \\prod_{n=1}^N \\mathcal N(t_n|y(x_n, \\boldsymbol w), \\beta^{-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然，处理极大化对数似然函数更为方便，即\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ln p(\\mathbf t | \\mathbf x, \\boldsymbol w, \\beta) &= \\ln \\prod_{n=1}^N \\frac{\\beta^{1/2}}{(2\\pi)^{1/2}} \\exp\\left(-\\frac{\\beta(y(x_n, \\boldsymbol w)-t_n)^2}{2}\\right)\\\\\n",
    "&=-\\frac\\beta2\\sum_{n=1}^N\\left\\{y(x_n, \\boldsymbol w)-t_n\\right\\}^2+\\frac N2 \\ln \\beta - \\frac N2 \\ln (2\\pi)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欲求极大化对数似然问题\n",
    "$$\n",
    "(\\boldsymbol w_{ML}, \\beta_{ML}) = {\\arg max}_{\\boldsymbol w, \\beta} \\ln p(\\mathbf t | \\mathbf x, \\boldsymbol w, \\beta),\n",
    "$$\n",
    "可通过梯度算得极值点：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial }{\\partial w_j}\\ln p(\\mathbf t | \\mathbf x, \\boldsymbol w, \\beta)\n",
    "& = -\\beta  \\sum_{n=1}^N x_n^j \\{y(x_n, \\boldsymbol w)-t_n\\} = 0, j=0,\\cdots, M\\\\\n",
    "\\frac{\\partial }{\\partial \\beta}\\ln p(\\mathbf t | \\mathbf x, \\boldsymbol w, \\beta) \n",
    "&= -\\frac12\\sum_{n=1}^N\\left\\{y(x_n, \\boldsymbol w)-t_n\\right\\}^2+\\frac N2 \\beta^{-1}=0\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重写上述的第一个式子可得\n",
    "$$\n",
    "\\mathbf A^T (\\mathbf A \\boldsymbol w - \\mathbf t) = 0\n",
    "$$\n",
    "此即之前用平方和误差函数所得到的法方程组。\n",
    "\n",
    "因此，**在高斯噪声的假设下，平方和误差函数是极大化似然然函数的一个自然结果。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由第二个式子可得\n",
    "$$\n",
    "\\beta_{ML}^{-1} = \\frac1{N} \\sum_{n=1}^N\\left\\{y(x_n, \\boldsymbol w)-t_n\\right\\}^2\n",
    "$$\n",
    "这说明，一旦确定了控制均值的参数$\\boldsymbol w_{ML}$，就可以用上式来确定精度$\\beta_{ML}$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定了参数$\\boldsymbol w$和$\\beta$后，就可以对新变量$x$的值进行预测。由于现在已经有了一个概率模型，预测可以通过$t$概率分布的预测分布（prediction distribution）来表示，即\n",
    "$$\n",
    "p(t|x, \\boldsymbol w_{ML}, \\beta_{ML}) = \\mathcal N(t | y(x, \\boldsymbol w_{ML}), \\beta_{ML}^{-1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更进一步，基于贝叶斯观点，我们可以对$\\boldsymbol w$引入先验分布。为简单起见，我们考虑如下形式的高斯分布：\n",
    "$$\n",
    "p(\\boldsymbol w|\\alpha) = \\mathcal N(\\boldsymbol w| \\boldsymbol 0, \\alpha^{-1}\\boldsymbol I)\n",
    "=\\left(\\frac{\\alpha}{2\\pi}\\right)^{\\frac{M+1}2}\\exp\\left\\{-\\frac\\alpha2\\boldsymbol w^T\\boldsymbol w\\right\\}\n",
    "$$\n",
    "其中$\\alpha$为分布的精度（为超参数，hyperparameters），$M+1$为参数向量$\\boldsymbol w$的维数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"image/Figure1.17.png\" width = 50% height = 50% />   \n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信息论 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息量 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于一个离散的随机变量$X$，当观察到它的一个值，能给我们带来多少信息呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息量可以理解为观察到$X$的这个值带来的“惊讶”程度。我们被告知一个不太可能发生的事发生了要比告知一个非常可能发生的事发生，我们获得信息要多。例如：\n",
    "\n",
    "* “太阳从东方升起”：信息量为$0$，是句废话：）\n",
    "* “武汉下雪了”：信息量较大\n",
    "\n",
    "因此，信息量的大小依赖于概率分布$p(X)$，即概率越低，信息量越大。于是，可用关于$p(X)$的一个函数来建模信息量$h(X)$。\n",
    "那什么函数模型适合表达呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑两个相互独立的事件$X$和$Y$，它们同时发生的信息量应该等于各自发生的信息量之和，即\n",
    "$$\n",
    "h(X,Y) = h(X)+h(Y),\n",
    "$$\n",
    "而两个独立事件$X, Y$的概率满足\n",
    "$$\n",
    "p(X,Y)=p(X)p(Y).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于上述观察可知，信息量应该与$\\log p(X)$有关，从而有\n",
    "$$\n",
    "h(X) = -\\log_2p(X),\n",
    "$$\n",
    "取负号有两个原因：\n",
    "1. $h(X)$关于$p(X)$为单调递减函数，即一个小概率事件具有更高的信息量；\n",
    "2. 保证信息量非负。\n",
    "\n",
    "$\\log$的底数可以任意，但信息论中一般取$2$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息熵 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "信息熵是跟所有可能性关系，而每个可能事件的发生都有个概率。信息熵就是平均而言发生一个事件我们得到的信息量大小。所以数学上，信息熵其实是信息量的期望：\n",
    "$$\n",
    "H(X) = -\\sum_{X} p(X)\\ln p(X),\n",
    "$$\n",
    "也称随机变量$X$的熵，它在信息论中表示随机变量不确定性的度量。注意到$\\lim_{p\\to 0}p \\ln p = 0$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例：考虑一个随机变量$X$，它由$8$种可能的状态$\\{a,b,c,d,e,f,g,h\\}$。\n",
    "* 若各状态是等可能的，即\n",
    "  $$\n",
    "  p(X=a) = \\cdots = p(X=h) = \\frac18\n",
    "  $$\n",
    "* 若各状态的概率分别为\n",
    " $$\n",
    " \\begin{aligned}\n",
    " p(X=a) = \\frac12, \\ \n",
    " p(X=b) = \\frac14, \\ \n",
    " p(X=c) = \\frac18, \\ \n",
    " p(X=d) = \\frac1{16}\\\\\n",
    " p(X=e) = p(X=f) = p(X=g) = p(X=h) = \\frac1{64}\n",
    " \\end{aligned}\n",
    " $$\n",
    " 试求这两种情况下随机变量$X$的熵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解：\n",
    "\n",
    "\n",
    "* 等可能性条件下，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H[x] = - 8 \\times \\frac18 \\log_2 \\frac18 = 3 ~\\mathrm{bits}\n",
    "\\end{aligned}\n",
    "$$\n",
    "* 第二种情况下，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H[x] &= -\\frac12\\log_2\\frac12-\\frac14\\log_2\\frac14-\\frac18\\log_2\\frac18-\\frac1{16}\\log_2\\frac1{16}-4\\times \\frac1{64}\\log_2\\frac1{64} = 2~\\mathrm{bits}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上例可以看出，非均匀分布的熵比均匀分布要小。后面我们会利用无序程度来讨论熵，届时会获得一些更深刻的认识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵的概念最早起源于物理学，是在热力学平衡的背景中介绍的。后来，在统计力学中，熵用来描述无序程度的度量。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设有一堆完全相同的球，共$n$个。现在想把这些球分到若干个箱子中，使得第$i$个箱子中有$n_i$个球。\n",
    "\n",
    "考虑把球分配到箱子中的不同方案的数量（无放回）：\n",
    "\n",
    "* 有$n$种方式选择第一个球，\n",
    "* 有$n-1$种方式选择第二个物体，\n",
    "*  $\\cdots\\cdots$\n",
    "\n",
    "因此共有$n!$种方式把$n$个物体分配到箱子中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而，我们并不想区分每个箱子内部物体的排列方式。在第$i$个箱子中，有$n_i!$种方式对物体重新排序，因此，把$n$个物体分配到箱子中的总方案数为\n",
    "$$\n",
    "W = \\frac{n!}{\\prod_i n_i!}\n",
    "$$\n",
    "它被称为乘数（multiplicity）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵被定义为\n",
    "$$\n",
    "H = \\frac1n\\ln W = \\frac{\\ln n!}n  - \\sum_i  \\frac{\\ln n_i! }n \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令$n\\to \\infty$，并假设\n",
    "$$\n",
    "\\lim_{n\\to \\infty} \\frac{n_i}n  = p_i,\n",
    "$$\n",
    "它表示一个球被分到第$i$个箱子的概率。\n",
    "此时有\n",
    "$$\n",
    "n_i\\to \\infty ~~ \\mathrm{as} ~~ n\\to \\infty.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用Stirling公式\n",
    "$$\n",
    "\\ln n! \\simeq n\\ln n - n  ~~ \\Rightarrow ~~ \\frac{\\ln n!}n \\simeq \\ln n-1\n",
    "$$\n",
    "可得\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H &= \\lim_{n\\to\\infty} \\left\\{ \\ln n-1 - \\frac1n \\sum_i (n_i\\ln n_i - n_i)\\right\\}\\\\\n",
    "&= \\lim_{n\\to\\infty} \\left\\{ \\ln n - \\sum_i \\frac{n_i}n \\ln n_i  \\right\\}\\\\\n",
    "&= \\lim_{n\\to\\infty} \\left\\{ \\sum_i \\frac{n_i}n \\ln n - \\sum_i \\frac{n_i}n \\ln n_i \\right\\}\\\\\n",
    "&= - \\lim_{n\\to\\infty}  \\sum_i \\frac{n_i}n \\ln \\frac{n_i}n  \\\\\n",
    "&= -   \\sum_i p_i \\ln p_i\n",
    "\\end{aligned}\n",
    "$$\n",
    "这里用到了$\\sum_i n_i = n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "物理学中，\n",
    "\n",
    "* 箱子中球的具体分配方案被称为微观状态（microstate）\n",
    "\n",
    "* 比值$\\frac{n_i}n$被称为宏观状态（macrostate）\n",
    "\n",
    "* $W$被称为宏观状态的权重\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若把箱子表述成离散随机变量$X$的状态$x_i$，其中$p(X = xi) = pi$，则$X$的熵为\n",
    "$$\n",
    "H[p] = -\\sum_i p(x_i) \\ln p(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在条件$\\sum_i p(x_i)=1$下，利用Lagrange乘子法可以确定出熵$H[p]$的最大值，即求\n",
    "$$\n",
    "\\widetilde{H} [p] =   -\\sum_i p(x_i) \\ln p(x_i) - \\lambda\\left(\\sum_i p(x_i)-1\\right)\n",
    "$$\n",
    "的极大值。对上式关于$p(x_)$求导并置之为零，可得\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial \\widetilde{H} }{\\partial p(x_i)} =   - \\left[\\ln p(x_i)+1\\right] - \\lambda = 0, \n",
    "\\end{aligned}\n",
    "$$\n",
    "即\n",
    "$$\n",
    "\\begin{aligned}\n",
    "   - \\ln p(x_i)-1 = \\lambda,  \n",
    "   \\end{aligned}\n",
    "\\quad\n",
    "\\Rightarrow \\quad\n",
    "\\begin{aligned}\n",
    "     p(x_i)  = e^{-\\lambda-1},  \n",
    "\\end{aligned}\n",
    "$$\n",
    "亦即\n",
    "$$\n",
    "p(x_1) = \\cdots = p(x_M) = \\frac1M.\n",
    "$$\n",
    "此时熵取到极大值$H=\\ln M$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td ><center><img src=\"image/Figure1.30a.png\" width = 50% height = 50% /></center></td>\n",
    "        <td ><center><img src=\"image/Figure1.30b.png\" width = 50% height = 50% /></center></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续随机变量$x$的熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设连续随机变量$x$的分布为$p(x)$，由积分中值定理，必存在$x_i\\in (i\\Delta, (i+1)\\Delta)$使得\n",
    "$$\n",
    "\\int_{i\\Delta}^{(i+1)\\Delta} p(x)\\,dx = p(x_i) \\Delta\n",
    "$$\n",
    "现在我们可以这样来量化$x$：只要$x$落在第$i$个箱子，就把$x$赋为$x_i$，于是观察到$x_i$的概率为$p(x_i) \\Delta$，这就变成了离散的分布。此时，熵的形式为\n",
    "$$\n",
    "H_\\Delta = -\\sum_i p(x_i) \\Delta \\ln p(x_i) \\Delta \n",
    "=  -\\sum_i p(x_i) \\Delta \\ln p(x_i) - \\ln \\Delta \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不考虑上式右端的第二项，令$\\Delta\\to 0$，则有\n",
    "$$\n",
    "\\lim_{\\Delta \\to 0} \\left\\{-\\sum_i p(x_i) \\Delta \\ln p(x_i) \\right\\} = \\int p(x)\\ln p(x)\\,dx\n",
    "$$\n",
    "该式称为微分熵（differential entropy）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
